{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0966ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fba4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(file_name):\n",
    "    # 定义正则表达式模式，匹配带故障的文件名\n",
    "    pattern_faulty = re.compile(r'(\\d+)k_(\\w+)_([\\w@]+)_(\\d+)_(\\d+)\\.mat')\n",
    "\n",
    "    # 定义正则表达式模式，匹配正常文件名\n",
    "    pattern_normal = re.compile(r'normal_(\\d+)_(\\d+)\\.mat')\n",
    "\n",
    "    # 尝试匹配故障文件名\n",
    "    match_faulty = pattern_faulty.match(file_name)\n",
    "    if match_faulty:\n",
    "        # 提取匹配的信息\n",
    "        sample_frequence = int(match_faulty.group(1))  # 转速\n",
    "        drive_end = match_faulty.group(2)   # 驱动端\n",
    "        fault_info = match_faulty.group(3)  # 故障信息\n",
    "        severity = int(match_faulty.group(4))  # 严重程度\n",
    "        trial_number = int(match_faulty.group(5))  # 试验编号\n",
    "\n",
    "        return {\n",
    "            'Type': 'Faulty',\n",
    "            'Sample Frequence': sample_frequence,\n",
    "            'Drive End': drive_end,\n",
    "            'Fault Info': fault_info,\n",
    "            'Load': severity,\n",
    "            'Trial Number': trial_number\n",
    "        }\n",
    "    else:\n",
    "        # 尝试匹配正常文件名\n",
    "        match_normal = pattern_normal.match(file_name)\n",
    "        if match_normal:\n",
    "            # 提取匹配的信息\n",
    "            severity = int(match_normal.group(1))  # 严重程度\n",
    "            trial_number = int(match_normal.group(2))  # 试验编号\n",
    "\n",
    "            return {\n",
    "                'Type': 'Normal',\n",
    "                'Load': severity,\n",
    "                'Trial Number': trial_number\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Filename '{file_name}' does not match any pattern.\")\n",
    "            return None\n",
    "\n",
    "# # 测试文件名\n",
    "# file_names = ['12k_Drive_End_IR028_3_3004.mat', '12k_Drive_End_OR007@6_0_130.mat', '48k_Drive_End_B007_3_125.mat', 'normal_0_97.mat']\n",
    "\n",
    "# # 提取信息并打印\n",
    "# for file_name in file_names:\n",
    "#     info = extract_info_from_filename(file_name)\n",
    "#     if info:\n",
    "#         print(f\"\\nInformation extracted from '{file_name}':\")\n",
    "#         for key, value in info.items():\n",
    "#             print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mat_files(folder_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    speed= []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mat\"):\n",
    "            infomationOfFilename=extract_info_from_filename(filename)\n",
    "            print(infomationOfFilename)\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            mat_data = loadmat(file_path)\n",
    "#             print(mat_data)\n",
    "            \n",
    "            # 这里假设MAT文件中有一个数组变量名为'data'，你可以根据实际情况修改\n",
    "            mat_variable_data = mat_data.get('X'+str(infomationOfFilename[\"Trial Number\"])+\"_DE_time\", None)\n",
    "            if infomationOfFilename[\"Trial Number\"]>=100:\n",
    "                mat_variable_data = mat_data.get('X'+str(infomationOfFilename[\"Trial Number\"])+\"_DE_time\", None)\n",
    "                mat_speed = mat_data.get('X'+str(infomationOfFilename[\"Trial Number\"])+\"RPM\", None)\n",
    "            else:\n",
    "                mat_variable_data = mat_data.get('X'+\"0\"+str(infomationOfFilename[\"Trial Number\"])+\"_DE_time\", None)\n",
    "                mat_speed = mat_data.get('X'+\"0\"+str(infomationOfFilename[\"Trial Number\"])+\"RPM\", None)\n",
    "            if mat_variable_data is not None:\n",
    "                # 将数组数据转换为一维数组或一维列表，具体取决于你的需求\n",
    "                flattened_data = mat_variable_data.flatten()\n",
    "                data.append(flattened_data)\n",
    "                labels.append(filename)\n",
    "                if mat_speed is not None:\n",
    "                    speed.append(mat_speed[0][0])\n",
    "                else:\n",
    "                    speed.append(0)\n",
    "                \n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'data': data, 'label': labels,\"speed\":speed})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e22dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定包含MAT文件的文件夹路径\n",
    "folder_path = 'H:\\project\\data\\cwru\\CaseWesternReserveUniversityData'\n",
    "\n",
    "# 读取MAT文件并创建DataFrame\n",
    "df = read_mat_files(folder_path)\n",
    "\n",
    "# 打印DataFrame的前几行\n",
    "print(df.head())\n",
    "df.to_csv(\"cwru_DE_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6404f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_data_path = folder_path+r\"\\normal_1_98.mat\"\n",
    "mat_data = loadmat(tem_data_path)\n",
    "mat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa03a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data = df.iloc[10, 0]\n",
    "cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb67e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制波形\n",
    "plt.plot(cell_data)\n",
    "plt.title('Vibration Data Waveform')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbc93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_OR(input_str):\n",
    "    #识别str是否是out ring的故障类型\n",
    "    pattern = re.compile(r'^[A-Z]{2}\\d{3}@\\d{1,2}$')\n",
    "    return bool(pattern.match(input_str))\n",
    "\n",
    "all_labels = ['B007','B014','B021','IR007','IR014','IR021','OR007@6','OR014@6','OR021@6']\n",
    "#随机生成训练集和测试集lables，并打印区别\n",
    "num_labels_to_select = random.randint(5, 8)\n",
    "trainlabels = random.sample(all_labels, num_labels_to_select)\n",
    "testlabels = random.sample(all_labels, num_labels_to_select)\n",
    "trainlabels.append(\"normal\")\n",
    "testlabels.append(\"normal\")\n",
    "all_labels.append(\"normal\")\n",
    "print(list(set(trainlabels).symmetric_difference(set(testlabels))))#应该先求交后求差\n",
    "\n",
    "def build_dataset(df,all_labels,trainlabels,testlabels):\n",
    "    # 读取MAT文件并创建DataFrame\n",
    "    #设置参数\n",
    "    load = 0\n",
    "    filepath = \"train.csv\"\n",
    "    \n",
    "#     all_labels_idex = [0,1,2,3,4,5,6,7,8,9]\n",
    "    train_ratio = 0.7\n",
    "    #初始化中间变量\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    #构建测试集和训练集，使用采样频率为12k的drive_end数据\n",
    "    for i in range(df.shape[0]):\n",
    "        file_info = extract_info_from_filename(df.loc[i][\"label\"])\n",
    "        if file_info[\"Type\"]!=\"Normal\":\n",
    "            if file_info['Sample Frequence']==12 and file_info['Drive End'] ==\"Drive_End\":               \n",
    "                if file_info['Load']==load:                  \n",
    "                    if validate_OR(file_info['Fault Info']) :\n",
    "                        #使用OR的6方向\n",
    "                        if file_info['Fault Info'].split('@')[1]==\"3\" or file_info['Fault Info'].split('@')[1]==\"12\":\n",
    "                            continue                    \n",
    "#                     print(file_info)\n",
    "#                     if file_info['Fault Info'] in trainlabels:\n",
    "                    train_data.append(df.loc[i][\"data\"][:int(len(df.loc[i][\"data\"])*train_ratio)])\n",
    "                    train_label.append(all_labels.index(file_info[\"Fault Info\"]))#使用故障类型在all_labels中的index作为y值，下同                    \n",
    "#                     if file_info['Fault Info'] in testlabels:\n",
    "                    test_data.append(df.loc[i][\"data\"][int(len(df.loc[i][\"data\"])*train_ratio)+1:])\n",
    "                    test_label.append(all_labels.index(file_info[\"Fault Info\"]))\n",
    "        #将normal数据加入训练集,normal的代号为9             \n",
    "        if file_info[\"Type\"]==\"Normal\" and file_info[\"Load\"]==load:\n",
    "            train_data.append(df.loc[i][\"data\"][:int(len(df.loc[i][\"data\"])*train_ratio)])\n",
    "            train_label.append(9)\n",
    "            test_data.append(df.loc[i][\"data\"][int(len(df.loc[i][\"data\"])*train_ratio)+1:])\n",
    "            test_label.append(9)\n",
    "#     输出csv\n",
    "    train = pd.DataFrame({\"data\":train_data,\"label\":train_label})\n",
    "    train.to_csv(filepath) \n",
    "    test = pd.DataFrame({\"data\":test_data,\"label\":test_label})\n",
    "    test.to_csv(\"test.csv\") \n",
    "    #返回dataframe类型的训练集和测试集数据\n",
    "    return train,test\n",
    "\n",
    "train,test = build_dataset(df,all_labels,trainlabels,testlabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd96034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test.iloc[0,0]))\n",
    "print(len(train.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a26d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c8fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_time_series(time_series):\n",
    "    #设置参数\n",
    "    segment_length = 1024\n",
    "    step = 30\n",
    "#     初始化中间变量\n",
    "    segments = []\n",
    "    for i in range(0, len(time_series), step):\n",
    "        segment = time_series[i:i + segment_length]\n",
    "        if len(segment) == segment_length:\n",
    "            segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "def create_testdataset(train,test,all_labels,train_labels,test_labels,phase = \"test\"):\n",
    "    #初始化中间变量\n",
    "    data = []\n",
    "    labels = []\n",
    "    testdata = []\n",
    "    testlabels = []\n",
    "    for i in range(train.shape[0]): \n",
    "        if phase ==\"train\" and all_labels[train.iloc[i,1]] in train_labels:\n",
    "            segments = segment_time_series(train.iloc[i,0])\n",
    "            data.extend(segments)\n",
    "            labels.extend([train.iloc[i,1]]*len(segments))            \n",
    "            segments = segment_time_series(test.iloc[i,0])\n",
    "            testdata.extend(segments)\n",
    "            testlabels.extend([test.iloc[i,1]]*len(segments))\n",
    "        if phase ==\"test\" and all_labels[test.iloc[i,1]] in test_labels:#加入测试阶段测试集数据，包括normal\n",
    "            segments = segment_time_series(test.iloc[i,0])\n",
    "            testdata.extend(segments)\n",
    "            testlabels.extend([test.iloc[i,1]]*len(segments))\n",
    "    if phase ==\"train\":    \n",
    "        np.save(\"train_train\"+\"_x.npy\", np.array(data))\n",
    "        np.save(\"train_train\"+\"_y.npy\", np.array(labels))\n",
    "        np.save(\"train_test\"+\"_x.npy\", np.array(testdata))\n",
    "        np.save(\"train_test\"+\"_y.npy\", np.array(testlabels))\n",
    "    if phase ==\"test\":    \n",
    "        np.save(\"test_test\"+\"_x.npy\", np.array(testdata))\n",
    "        np.save(\"test_test\"+\"_y.npy\", np.array(testlabels))\n",
    "   \n",
    "         \n",
    "create_testdataset(train,test,all_labels,trainlabels,testlabels,phase = \"train\") \n",
    "create_testdataset(train,test,all_labels,trainlabels,testlabels,phase = \"test\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1b5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载数据集\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train = np.load('traindataset.npy',allow_pickle=True)\n",
    "test = np.load('testdataset.npy',allow_pickle=True) \n",
    "\n",
    "# 假设有一个包含开集的训练集\n",
    "print(train)\n",
    "train_dataset = train\n",
    "test_dataset = test\n",
    "\n",
    "# 2. 将训练集划分为训练集和开集\n",
    "# train_data, open_set_data, _, _ = train_test_split(train_dataset, train_size=0.8, random_state=42, stratify=train_dataset.targets)\n",
    "\n",
    "# 3. 构建模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 类别用于训练\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 4. 训练模型\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# 5. 训练集和开集的 DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "open_set_loader = DataLoader(open_set_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# 6. 训练模型\n",
    "model = SimpleCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, epochs=5)\n",
    "\n",
    "# 7. 在开集上测试\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in open_set_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on Open Set: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030895d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
